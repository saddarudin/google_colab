{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzdTw0pMAkLt5ytBP8fjs+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saddarudin/google_colab/blob/main/nlp_stemming_lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2oukFTE1Nczf"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming in NLTK"
      ],
      "metadata": {
        "id": "bk1-MSIERR9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "words = ['eating','eats','eat','ate','adjustable','rafting','ability','meeting']\n",
        "\n",
        "for word in words:\n",
        "  print(word, '|', stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K80uDb2OQYeb",
        "outputId": "560f3cd4-f5fb-428d-c3fc-85d819d44162"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eat\n",
            "eats | eat\n",
            "eat | eat\n",
            "ate | ate\n",
            "adjustable | adjust\n",
            "rafting | raft\n",
            "ability | abil\n",
            "meeting | meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization in NLTK"
      ],
      "metadata": {
        "id": "lll9pDMbRT8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization in NLTK\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # For additional language support\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = ['eating','eats','eat','ate','adjustable','rafting','ability','meeting']\n",
        "\n",
        "for word in words:\n",
        "  print(word, '|', lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv3CjCzOQ_se",
        "outputId": "ff23cfd3-9527-44b5-aa80-6729b47449f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eating\n",
            "eats | eats\n",
            "eat | eat\n",
            "ate | ate\n",
            "adjustable | adjustable\n",
            "rafting | rafting\n",
            "ability | ability\n",
            "meeting | meeting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization in spaCy"
      ],
      "metadata": {
        "id": "ygMUX2dCRwLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp('eating eats eat ate adjustable rafting ability meeting better')\n",
        "\n",
        "for token in doc:\n",
        "  print(token, '|', token.lemma_, '|', token.lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKRDcMQDRzKa",
        "outputId": "d8cefc7f-4873-4262-cf9e-62bdb7bccd0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eat | 9837207709914848172\n",
            "eats | eat | 9837207709914848172\n",
            "eat | eat | 9837207709914848172\n",
            "ate | eat | 9837207709914848172\n",
            "adjustable | adjustable | 6033511944150694480\n",
            "rafting | raft | 7154368781129989833\n",
            "ability | ability | 11565809527369121409\n",
            "meeting | meet | 6880656908171229526\n",
            "better | well | 4525988469032889948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Mando talked 3 hours although talking isn't his thing he became talkative\")\n",
        "for token in doc:\n",
        "  print(token, '|', token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toua1mtuSKCr",
        "outputId": "126f0c2c-2895-4020-eed8-21fff28caf82"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mando | Mando\n",
            "talked | talk\n",
            "3 | 3\n",
            "hours | hour\n",
            "although | although\n",
            "talking | talk\n",
            "is | be\n",
            "n't | not\n",
            "his | his\n",
            "thing | thing\n",
            "he | he\n",
            "became | become\n",
            "talkative | talkative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customizing the model"
      ],
      "metadata": {
        "id": "GBTTQNluTSWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I'm exhausted\")\n",
        "# In above sentence Bro, Brah both point to Brother but the model treat them as as they are\n",
        "\n",
        "for token in doc:\n",
        "  print(token, '|', token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dqe8DQ2S7vl",
        "outputId": "d5eb48c1-88b5-479d-a563-7a0f28ef5d55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | Bro\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Brah | Brah\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "'m | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar = nlp.get_pipe('attribute_ruler')\n",
        "ar.add([[{'Text':'Bro'}],[{'Text':'Brah'}]],{'LEMMA':'Brother'})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I'm exhausted\")\n",
        "for token in doc:\n",
        "  print(token, '|', token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSTAcrUgTxhH",
        "outputId": "f5058936-1d4f-4e68-c8bb-18a7c9277732"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | Brother\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Brah | Brother\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "'m | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cvbj6fCzUZIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}